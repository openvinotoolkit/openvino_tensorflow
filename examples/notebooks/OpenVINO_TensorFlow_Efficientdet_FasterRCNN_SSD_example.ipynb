{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a40d338",
   "metadata": {},
   "source": [
    "# Object Detection with [OpenVINO™ integration with TensorFlow](https://github.com/openvinotoolkit/openvino_tensorflow)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898d9206",
   "metadata": {},
   "source": [
    "[OpenVINO™ integration with TensorFlow](https://github.com/openvinotoolkit/openvino_tensorflow) is designed for TensorFlow developers who want to get started with [OpenVINO™](https://www.intel.com/content/www/us/en/developer/tools/openvino-toolkit/overview.html) in their inferencing applications. This product effectively delivers OpenVINO™ inline optimizations, which enhance inferencing performance with minimal code modifications. OpenVINO™ integration with TensorFlow accelerates inference across many AI models on a variety of Intel® silicon such as:\n",
    "\n",
    " - Intel® CPUs\n",
    " - Intel® integrated GPUs\n",
    " - Intel® Movidius™ Vision Processing Units - referred to as VPU\n",
    " - Intel® Vision Accelerator Design with 8 Intel Movidius™ MyriadX VPUs - referred to as VAD-M or HDDL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0bdaa7e",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "\n",
    "* [About this sample](#About-this-Sample)\n",
    "\n",
    "* [Prerequisites](#Prerequisites)\n",
    "* [About the models](#About-the-models)\n",
    "     * [EfficientDet_d6_coco17_tpu-32](#EfficientDet_d6_coco17_tpu-32)\n",
    "     * [Faster_rcnn_resnet152_v1_640x640_coco17_tpu-8](#Faster_rcnn_resnet152_v1_640x640_coco17_tpu-8)\n",
    "     * [SSD_resnet50_v1_fpn_640x640_coco17_tpu-8](#SSD_resnet50_v1_fpn_640x640_coco17_tpu-8)\n",
    "* [Getting Started](#Getting-Started)\n",
    "    * [Install OpenVINO integration with TensorFlow](#Install-OpenVINO%E2%84%A2-integration-with-TensorFlow)\n",
    "    * [Import required packages](#Import-required-packages)\n",
    "* [Set up Object Detection API](#Set-up-Object-Detection-API)\n",
    "    * [Clone TensorFlow-models GitHub repository](#Clone-TensorFlow-models-:-GitHub-Repository)\n",
    "    * [Install Object Detection API](#Install-Object-Detection-API)\n",
    "    * [Set Labels](#Set-Labels)\n",
    "* [Get Models and Inputs](#Get-Models-and-Inputs)\n",
    "    * [Set models and images](#Set-models-and-images)\n",
    "    * [Download model](#Download-model)\n",
    "    * [Get Model and image details](#Get-Model-and-image-details)\n",
    "* [Define Input processing methods](#Define-Input-processing-methods)\n",
    "    * [Define load model](#Define-load-model)\n",
    "    * [Define load image](#Define-load-image)\n",
    "    * [IR files Generation](#IR-files---Generation)\n",
    "* [Define Output processing methods](#Define-Output-processing-methods)\n",
    "    * [Get Colours](#Get-Colours)\n",
    "    * [Get Coordinates](#Get-Coordinates)\n",
    "    * [Add labels](#Add-labels)\n",
    "    * [Draw bounding boxes](#Draw-bounding-boxes)\n",
    "    * [Visualize Outputs](#Visualize-Outputs)\n",
    "* [Define Inference](#Define-Inference)\n",
    "    * [Run inference on OpenVINO TensorFlow and TensorFlow](#Run-inference-on-OpenVINO_TensorFlow-and-TensorFlow)\n",
    "    * [Model benchmarking on Native OpenVINO](#Model-benchmarking-on-Native-OpenVINO)\n",
    "* [Let's try inference](#Let's-try-inference)\n",
    "    * [With OpenVINO integration with TensorFlow enabled](#With-OpenVINO%E2%84%A2-integration-with-TensorFlow-enabled)\n",
    "    * [With OpenVINO integration with TensorFlow disable (TensorFlow)](#With-OpenVINO%E2%84%A2-integration-with-TensorFlow-disabled-(TensorFlow))\n",
    "    * [With Native OpenVINO](#Native-OpenVINO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee1e94e",
   "metadata": {},
   "source": [
    "## About this Sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf17f91",
   "metadata": {},
   "source": [
    "This sample showcases object detection in images using **Efficientdet_d6_coco17_tpu-32**, **Faster_rcnn_resnet152_v1_640x640_coco17_tpu-8** and **SSD_resnet50_v1_fpn_640x640_coco17_tpu-8** TensorFlow Models to see the performance and inference results using TensorFlow, OpenVINO Integration with TensorFlow and Native OpenVINO. \n",
    "\n",
    "In the start, all the models and input images are downloaded and set respectively. Next, we load the models and images to be passed to TensorFlow, OpenVINO_TensorFlow and OpenVINO that allow you to run inference on Intel hardware. After inference, the output detections are visualized. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f8d874",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "### This sample requires the following:\n",
    "**Note**: All the prerequisites are available in this notebook and a procedure to fetch them is also explained.\n",
    "\n",
    " - Models: Download and use for benchmarking.\n",
    " - Input_image: Test image used from tensorflow/models GitHub repo. You can also specify your own image as test image in [Set models and images](#Set-models-and-images) section.\n",
    " - [tensorflow/models](#Clone-TensorFlow-models-:-GitHub-Repository) GitHub repo: To use 'mscoco_label_map.pbtxt' file for labelling detections.\n",
    " - \"./models/research/object_detection/data/[mscoco_label_map.pbtxt](#Set-Labels)\": To create labels file to label output detections.\n",
    " - IR files: IR format files used for benchmarking on Native OpenVINO. Process is explained in [IR files – Generation](#IR-files---Generation) section"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904cfc6b",
   "metadata": {},
   "source": [
    "## About the models "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d16c23",
   "metadata": {},
   "source": [
    "### EfficientDet_d6_coco17_tpu-32\n",
    "[EfficientDet_d6](https://tfhub.dev/tensorflow/efficientdet/d6/1) is an object detection model trained on the COCO 2017 dataset. This model is a combination of SSD with EfficientNet-b6 + BiFPN feature extractor, shared box predictor, and focal loss, which is published by [TensorFlow Hub](https://www.tensorflow.org/hub).\n",
    "\n",
    "Model's architecture is defined by [EfficientDet](https://arxiv.org/abs/1911.09070) created using [TensorFlow Object Detection API](https://github.com/tensorflow/models/tree/master/research/object_detection) and the model is available in TF2.0 saved model format.\n",
    "\n",
    "Model’s input is a three-channel image of variable size, input tensor is a tf.uint8 tensor with shape [1, height, width, 3] and returns an output dictionary containing 'number of detections', 'bounding box coordinates' in following order [ymin, xmin, ymax, xmax], 'detection scores', 'detection class index' from the label file, 'decoded detection boxes' without Non-Max suppression, 'class score logits' for raw detection boxes,'anchor indices' of the detections after NMS and others.\n",
    "\n",
    "**Note**: For more information about **EfficientDet_d6**, please refer to this [page](https://tfhub.dev/tensorflow/efficientdet/d6/1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261bacc2",
   "metadata": {},
   "source": [
    "### Faster_rcnn_resnet152_v1_640x640_coco17_tpu-8\n",
    "[Faster R-CNN with Resnet-152 V1](https://tfhub.dev/tensorflow/faster_rcnn/resnet152_v1_640x640/1) is an object detection model trained on the COCO 2017 dataset  with training images scaled to 640x640, which is published by [TensorFlow Hub](https://www.tensorflow.org/hub). \n",
    "\n",
    "Model's architecture is defined by Faster R-CNN, created using [TensorFlow Object Detection API](https://github.com/tensorflow/models/tree/master/research/object_detection) and is available in TF2.0 saved model format.\n",
    "\n",
    "Model’s input is a three-channel image of variable size, input tensor is a tf.uint8 tensor with shape [1, height, width, 3] and returns an output dictionary containing 'number of detections', 'bounding box coordinates' in following order [ymin, xmin, ymax, xmax], 'detection scores', 'detection class index' from the label file, 'decoded detection boxes' without Non-Max suppression, 'class score logits' for raw detection boxes,'anchor indices' of the detections after NMS and others.\n",
    "\n",
    "**Note**: For more information about **Faster_rcnn_resnet152_v1_640x640_coco17_tpu-8**, please refer to this [page](https://tfhub.dev/tensorflow/faster_rcnn/resnet152_v1_640x640/1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485ea6e3",
   "metadata": {},
   "source": [
    "### SSD_resnet50_v1_fpn_640x640_coco17_tpu-8\n",
    "[Retinanet (SSD with Resnet 50 v1)](https://tfhub.dev/tensorflow/retinanet/resnet50_v1_fpn_640x640/1) is an object detection model trained on the COCO 2017 dataset with training images scaled to 640x640. The model is published by [TensorFlow Hub](https://www.tensorflow.org/hub).\n",
    "\n",
    "Model's architecture is defined by RetinaNet, created using [TensorFlow Object Detection API](https://github.com/tensorflow/models/tree/master/research/object_detection) and is available in TF2.0 saved model format.\n",
    "\n",
    "Model’s input is a three-channel image of variable size, input tensor is a tf.uint8 tensor with shape [1, height, width, 3] and returns an output dictionary containing 'number of detections', 'bounding box coordinates' in following order [ymin, xmin, ymax, xmax], 'detection scores', 'detection class index' from the label file, 'decoded detection boxes' without Non-Max suppression, 'class score logits' for raw detection boxes,'anchor indices' of the detections after NMS and others.\n",
    "      \n",
    "**Note**: For more information about **SSD_resnet50_v1_fpn_640x640_coco17_tpu-8**, please refer to this [page](https://tfhub.dev/tensorflow/retinanet/resnet50_v1_fpn_640x640/1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66430a8c",
   "metadata": {},
   "source": [
    "## Getting Started \n",
    "\n",
    "In this section, we install OpenVINO TensorFlow, necessary pip packages and import the packages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96840910",
   "metadata": {},
   "source": [
    "### Install [OpenVINO™ integration with TensorFlow](https://github.com/openvinotoolkit/openvino_tensorflow) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1445c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "root_path = os.getcwd()\n",
    "\n",
    "# Enable this variable for runtime inference optimizations\n",
    "os.environ[\"OPENVINO_TF_CONVERT_VARIABLES_TO_CONSTANTS\"] = \"1\"\n",
    "\n",
    "!python3 -m pip install --upgrade pip\n",
    "!python3 -m pip install opencv-python matplotlib scipy tensorflow_hub\n",
    "\n",
    "# Install TensorFlow (v2.9.1) and OpenVINO-TensorFlow (v2.1.0) only if they aren't found\n",
    "!python3 -m pip install tensorflow==2.9.1\n",
    "!python3 -m pip install openvino-tensorflow==2.1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3197e6be",
   "metadata": {},
   "source": [
    "**Note**: While using Windows, continue to install above mentioned pip packages and to install TensorFlow and  OpenVINO™ TensorFlow please use the following [steps](https://github.com/openvinotoolkit/openvino_tensorflow/blob/master/docs/INSTALL.md#windows) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524c95ec",
   "metadata": {},
   "source": [
    "### Import required packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ccf006",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import cv2\n",
    "import time\n",
    "import pathlib\n",
    "import colorsys\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.misc\n",
    "import numpy as np\n",
    "from six import BytesIO\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from six.moves.urllib.request import urlopen\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import openvino_tensorflow as ovtf\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0dbbdbb",
   "metadata": {},
   "source": [
    "## Set up Object Detection API\n",
    "\n",
    "Install Object Detection API and import the necessary packages for use in the following sections."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bdc3eb7",
   "metadata": {},
   "source": [
    "### Clone TensorFlow models : GitHub Repository\n",
    "Clone Tensorflow/models github repository to be used in the later section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498246e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone --depth 1 https://github.com/tensorflow/models.git #This repo is cloned to use in the later context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a5b77b",
   "metadata": {},
   "source": [
    "### Install Object Detection API "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f6eac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "sudo apt install -y protobuf-compiler\n",
    "cd models/research/\n",
    "protoc object_detection/protos/*.proto --python_out=.\n",
    "cp object_detection/packages/tf2/setup.py .\n",
    "python -m pip install ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00030cee",
   "metadata": {},
   "source": [
    "### Set Labels\n",
    "Here, we are importing 'label_map_util', which is necessary to get label details for the output images, as given in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9f49f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from object_detection.utils import label_map_util\n",
    "%matplotlib inline\n",
    "\n",
    "labels_path = \"./models/research/object_detection/data/mscoco_label_map.pbtxt\"\n",
    "labels = label_map_util.create_category_index_from_labelmap(labels_path, use_display_name=True) # Creating labels files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55d2f09",
   "metadata": {},
   "source": [
    "## Get Models and Inputs\n",
    "\n",
    "In this section, we focus on setting up the models and inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ad8626",
   "metadata": {},
   "source": [
    "###  Set models and images\n",
    "For Model:\n",
    "Create a nested 'models' dictionary which contains model's URL [which is a tar file] as 'model_url', once the model is downloaded and untar we save the models in location as 'model_dir', save model's size as 'model_size' to be used in models IR file generation and the generated IR files are saved in a directory as 'model_ir' required for Native OpenVINO inference.\n",
    "\n",
    "For Test image:\n",
    "We are using input images available from the tensorflow/models github repo as an example. **Note**: You can also specify any image that you wish to test the models on by adding the name and location/URL of the image into the below 'images' dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c09a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A nested dictionary of with above mentioned object detection models is created to be used in later sections\n",
    "\n",
    "models = {\n",
    "    \"efficientdet_d6_coco17_tpu-32\" : {'model_url' : 'http://download.tensorflow.org/models/object_detection/tf2/20200711/efficientdet_d6_coco17_tpu-32.tar.gz','model_dir' : 'download_models/efficientdet_d6_coco17_tpu-32/saved_model','model_size' : '512','model_ir' : 'ir_files/efficientdet_d6_coco17_tpu-32/saved_model.xml'},\n",
    "    \"faster_rcnn_resnet152_v1_640x640_coco17_tpu-8\" : {'model_url' : 'http://download.tensorflow.org/models/object_detection/tf2/20200711/faster_rcnn_resnet152_v1_640x640_coco17_tpu-8.tar.gz','model_dir' : 'download_models/faster_rcnn_resnet152_v1_640x640_coco17_tpu-8/saved_model', 'model_size' : '640','model_ir' : 'ir_files/faster_rcnn_resnet152_v1_640x640_coco17_tpu-8/saved_model.xml'},\n",
    "    \"ssd_resnet50_v1_fpn_640x640_coco17_tpu-8\" : {'model_url' : 'http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8.tar.gz', 'model_dir' : 'download_models/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/saved_model', 'model_size' : '640','model_ir' : 'ir_files/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/saved_model.xml'}\n",
    "\n",
    "}\n",
    "\n",
    "images = {\n",
    "    'Beach' : 'models/research/object_detection/test_images/image2.jpg',\n",
    "    'Dogs' : 'models/research/object_detection/test_images/image1.jpg'\n",
    "}\n",
    "\n",
    "input_image = images[\"Beach\"] #You can select the test image added in 'images' dictionary here. Like: images['your_test_image']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e533d23",
   "metadata": {},
   "source": [
    "### Get Model and image details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf6bd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_details(model_name):\n",
    "    if model_name in models:\n",
    "        return models[model_name]\n",
    "    \n",
    "def get_image(image_name):\n",
    "    if image_name in images:\n",
    "        return images[image_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd98194",
   "metadata": {},
   "source": [
    "### Download model\n",
    "Create a 'download_models' directory to download and save the models and untar them to use while model inferencing. Also, create 'output_images' directory to save the output images after model inferencing into that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0946dda6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if os.getcwd() == root_path and not os.path.exists(\"download_models\"):\n",
    "    path = os.path.join(os.getcwd(),\"download_models\")\n",
    "    os.mkdir(path)\n",
    "if os.getcwd() == root_path and not os.path.exists(\"output_images\"):\n",
    "    path = os.path.join(os.getcwd(),\"output_images\")\n",
    "    os.mkdir(path)\n",
    "    \n",
    "if not os.getcwd() == root_path+\"/download_models\":\n",
    "    os.chdir(\"download_models\") #changing to download_models directory\n",
    "if not os.listdir(os.getcwd()):\n",
    "    for model_name in models:\n",
    "        model_url = get_model_details(model_name)[\"model_url\"]\n",
    "        !wget \"$model_url\"\n",
    "    for model_tar in os.listdir(os.getcwd()):\n",
    "        !tar -zxvf \"$model_tar\"\n",
    "os.chdir(root_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc64718",
   "metadata": {},
   "source": [
    "## Define Input processing methods\n",
    "\n",
    "In this section, we define methods useful for image and model loading, which give the right input formats to be used in inferencing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d2179c",
   "metadata": {},
   "source": [
    "### Define load model \n",
    "In this section, we are loading the selected model using 'tensorflow_hub.load'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f46f823",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_name,input_model):\n",
    "  print(f\"\\nLoading {model_name}...\\n\")\n",
    "  model = hub.load(input_model)\n",
    "  print(f\"\\n{model_name} loaded successfully!\")\n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ca035d",
   "metadata": {},
   "source": [
    "### Define load image\n",
    "In this section, we use the image URL or direct image location to read and get the input tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f95ec33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(input_image):\n",
    "  print(\"Loading input image...\")  \n",
    "  image = None\n",
    "  if(input_image.startswith('https')):\n",
    "    response = urlopen(input_image)\n",
    "    image_data = response.read()\n",
    "    image_data = BytesIO(image_data)\n",
    "    image_data = Image.open(image_data)\n",
    "  else:\n",
    "    image_data = cv2.imread(input_image)\n",
    "\n",
    "  (img_width, img_height) = image_data.shape[1],image_data.shape[0]\n",
    "  print(\"Image loaded Successfully\")\n",
    "  return np.array([image_data], dtype = np.uint8), img_height, img_width"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ecf524d",
   "metadata": {},
   "source": [
    "### IR files - Generation \n",
    "Convert TensorFlow_hub 'saved_model' formats to 'IR' format using 'model optimizer : mo' available in openvino-dev package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2a2d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ir(model):\n",
    "    size = int(get_model_details(model)[\"model_size\"])\n",
    "    !source openvino_env/bin/activate && mo --saved_model_dir=\"$root_path/download_models/$model/saved_model\" --input_shape [1,\"$size\",\"$size\",3] --output_dir \"ir_files/$model\" --tensorflow_object_detection_api_pipeline_config \"$root_path/download_models/$model/pipeline.config\"\n",
    "    print(f\"\\nIR Generation successfully completed for {model}..!\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b00ab18",
   "metadata": {},
   "source": [
    "## Define Output processing methods\n",
    "\n",
    "In this section, we define methods useful post model inferencing to visualize the outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13f81c3",
   "metadata": {},
   "source": [
    "### Get Colours  \n",
    "Generate colors for drawing the bounding boxes detected. **Note**: This section is completely optional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7c5925",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_colors(class_names):\n",
    "    # Generate colors for drawing bounding boxes.\n",
    "    hsv_tuples = [\n",
    "        (x / len(class_names), 1., 1.) for x in range(len(class_names))\n",
    "    ]\n",
    "    colors = list(map(lambda x: colorsys.hsv_to_rgb(*x), hsv_tuples))\n",
    "    colors = list(\n",
    "        map(lambda x: (int(x[0] * 255), int(x[1] * 255), int(x[2] * 255)),\n",
    "            colors))\n",
    "    np.random.seed(10101)  # Fixed seed for consistent colors across runs.\n",
    "    np.random.shuffle(colors)  # Shuffle colors to decorrelate adjacent classes.\n",
    "    np.random.seed(None)  # Reset seed to default.\n",
    "    return colors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0f84f6",
   "metadata": {},
   "source": [
    "### Get Coordinates\n",
    "Define a method to get coordinate details of the detected bounding boxes to be drawn on the output image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f43baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coordinates(box, img_height, img_width):\n",
    "    return [int(box[0]*img_height),int(box[1]*img_width), int(box[2]*img_height), int(box[3]*img_width)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e47ada",
   "metadata": {},
   "source": [
    "### Add labels\n",
    "Define a method to add labels for the detected bounding boxes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfecf17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_label(image, text, color, coords):\n",
    "    font = cv2.FONT_HERSHEY_PLAIN\n",
    "    font_scale = 1.\n",
    "    (text_width, text_height) = cv2.getTextSize(\n",
    "        text, font, fontScale=font_scale, thickness=1)[0]\n",
    "\n",
    "    padding = 5\n",
    "    rect_height = text_height + padding * 2\n",
    "    rect_width = text_width + padding * 2\n",
    "\n",
    "    (x, y) = coords\n",
    "\n",
    "    cv2.rectangle(image, (x, y), (x + rect_width, y - rect_height), color,\n",
    "                  cv2.FILLED)\n",
    "    cv2.putText(\n",
    "        image,\n",
    "        text, (x + padding, y - text_height + padding),\n",
    "        font,\n",
    "        fontScale=font_scale,\n",
    "        color=(255, 255, 255),\n",
    "        lineType=cv2.LINE_AA)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a22c4b",
   "metadata": {},
   "source": [
    "### Draw bounding boxes\n",
    "Define a method for drawing the obtained bounding boxes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68db3273",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_boxes(image,\n",
    "               boxes,\n",
    "               classes,\n",
    "               scores,\n",
    "               class_names,\n",
    "               colors,\n",
    "               show_score=True):\n",
    "    if classes is None or len(classes) == 0:\n",
    "        return image\n",
    "\n",
    "    for box, cls, score in zip(boxes, classes, scores):\n",
    "        print(box)\n",
    "        ymin, xmin, ymax, xmax = box\n",
    "        \n",
    "        class_name = class_names[cls]\n",
    "        if show_score:\n",
    "            label = '{} {:.2f}'.format(class_name, score)\n",
    "        else:\n",
    "            label = '{}'.format(class_name)\n",
    "\n",
    "        # if no color info, use black(0,0,0)\n",
    "        if colors == None:\n",
    "            color = (0, 0, 0)\n",
    "        else:\n",
    "            color = colors[cls]\n",
    "        cv2.rectangle(image, (xmin, ymin), (xmax, ymax), color, 1, cv2.LINE_AA)\n",
    "#         print(label)\n",
    "        image = add_label(image, label, color, (xmin, ymin))\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64de4df0",
   "metadata": {},
   "source": [
    "### Visualize Outputs\n",
    "Define a method to visualize the predictions obtained through inferencing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e055d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_ouput(model_name,predictions,img_height,img_width,isovtf):\n",
    "    colors = get_colors(labels)\n",
    "    class_ids = predictions[\"detection_classes\"][0].numpy().astype(\"int\")\n",
    "    scores = predictions[\"detection_scores\"][0].numpy()\n",
    "    num_detections = predictions[\"num_detections\"][0].numpy().astype(\"int\")\n",
    "    detection_boxes = predictions[\"detection_boxes\"][0].numpy()\n",
    "    conf_threshold = 0.4 # You can try increase/decrease threshold to see the output changes\n",
    "    print(f\"num detection : {type(num_detections)}\")\n",
    "    print(f\"num detection : {num_detections}\")\n",
    "    boxes = []\n",
    "    confidence_scores = []\n",
    "    classes = []\n",
    "    for detection_index in range(num_detections):\n",
    "        if scores[detection_index]<conf_threshold:\n",
    "            continue\n",
    "        else:\n",
    "            confidence_scores.append(scores[detection_index])\n",
    "            classes.append(class_ids[detection_index])\n",
    "            boxes.append(get_coordinates(detection_boxes[detection_index], img_height, img_width))\n",
    "            \n",
    "    img_bbox = draw_boxes(cv2.imread(input_image), boxes, classes, scores,\n",
    "                        labels, colors)\n",
    "    if isovtf:\n",
    "        output_image_name = model_name +\"_OVTF\" +\"_detected_output\"\n",
    "    else:\n",
    "        output_image_name = model_name +\"_TF\" +\"_detected_output\"\n",
    "    cv2.imwrite(\"output_images/\"+output_image_name+\".png\", img_bbox)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9cde80",
   "metadata": {},
   "source": [
    "## Define Inference\n",
    "In this section, we define model inferencing methods run on TensorFlow, OpenVINO_TensorFlow and Native OpenVINO."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699fcd0b",
   "metadata": {},
   "source": [
    "### Run inference on OpenVINO_TensorFlow and TensorFlow\n",
    "Define model inferencing method, to run the selected model on OpenVINO_TensorFlow and TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f6a753",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inference(model,image):\n",
    "    \"\"\"Run inference to capture output and performance results\"\"\"\n",
    "    elapsed = 0.0\n",
    "    total_time = 0.0\n",
    "    num_iterations = 50 #You can increase/decrease number of iterations and see output changes\n",
    "\n",
    "    # run initial inference and capture the output\n",
    "    predictions = model(image)\n",
    "    \n",
    "    # capature the average performance results\n",
    "    for i in range(num_iterations):\n",
    "        start = time.time()\n",
    "        model(image)\n",
    "        elapsed = time.time() - start\n",
    "        total_time += elapsed\n",
    "    \n",
    "    # calculate average inference time over number of iterations in milliseconds\n",
    "    # and round the number to 2 decimal points\n",
    "    average_time = round((total_time/num_iterations)*1000,2)\n",
    "                \n",
    "    return predictions, average_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c75f618",
   "metadata": {},
   "source": [
    "### Model benchmarking on Native OpenVINO\n",
    "After obtaining IR files using 'IR files - Generation' section, we benchmark the models on Native OpenVINO, as in this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a542cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ov_run_infer(model,image):\n",
    "    size = get_model_details(model)['model_size']\n",
    "    ir = get_model_details(model)['model_ir']\n",
    "    !source openvino_env/bin/activate && benchmark_app -m=\"$ir\" -i $image -d CPU -niter 50 -nstreams 1 -nireq 1 -hint \"latency\" -shape \"[1,\"$size\",\"$size\",3]\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57bd36df",
   "metadata": {},
   "source": [
    "## Let's try inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56772c1b",
   "metadata": {},
   "source": [
    "### With OpenVINO™ integration with TensorFlow enabled\n",
    "Enable OpenVINO TensorFlow with OpenVINO_TensorFlow.enable() API and set backend name to run on OpenVINO_TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a955ecf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ovtf.enable() # Enable OpenVINO Tensorflow\n",
    "\n",
    "backend_name = \"CPU\" # Define the backend to be enabled\n",
    "\n",
    "print('Available Backends:') # Print list of available backends\n",
    "backends_list = ovtf.list_backends() # To determine available backends on your system, 'list_backends' API is used\n",
    "for backend in backends_list:\n",
    "    print(f\"\\t{backend}\")\n",
    "\n",
    "ovtf.set_backend(backend_name) # set the backend\n",
    "print(f\"\\nOpenVINO TensorFlow is enabled and device {backend_name} is set as backend.\\n\")\n",
    "\n",
    "image, img_height, img_width = load_image(input_image) # Loading the input_image\n",
    "\n",
    "# Running all the models iteratively\n",
    "for model_name in models:\n",
    "    input_model = get_model_details(model_name)[\"model_dir\"] # Get model location\n",
    "    model = load_model(model_name,input_model) # Loading the model\n",
    "    predictions,average_time = run_inference(model,image) # Running inference\n",
    "    visualize_ouput(model_name,predictions,img_height,img_width,1) # Visualizing the output # Here '1' is set to indicate model run on OVTF\n",
    "    print(f\"\\nInference Successfully completed on OpenVINO TensorFlow..! {model_name} model run on {backend_name} in {average_time} ms\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b12ed4",
   "metadata": {},
   "source": [
    "**Note**: Output image is obtained in 'output_images' directory as \"{model_name}_{OVTF}_detected_out.png\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b034917",
   "metadata": {},
   "source": [
    "### With OpenVINO™ integration with TensorFlow disabled (TensorFlow)\n",
    "Disable OpenVINO_TensorFlow with OpenVINO_TensorFlow.disable() API to run on TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b381bbc6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ovtf.disable() # Disable OpenVINO Tensorflow\n",
    "print(\"OpenVINO TensorFlow is disabled\\n\")\n",
    "\n",
    "\n",
    "backend_name = \"CPU\" # Define the backend\n",
    "\n",
    "\n",
    "image, img_height, img_width = load_image(input_image) # Loading the input_image\n",
    "for model_name in models:\n",
    "    input_model = get_model_details(model_name)[\"model_dir\"] # Get model location\n",
    "    model = load_model(model_name,input_model) # Loading the model\n",
    "    predictions,average_time = run_inference(model,image) # Running inference\n",
    "    visualize_ouput(model_name,predictions,img_height,img_width,0) # Visualizing the output # Here '0' is set to indicate model run on TF\n",
    "    print(f\"\\nInference Successfully completed on TensorFlow..! {model_name} model run on {backend_name} in {average_time} ms\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80539022",
   "metadata": {},
   "source": [
    "**Note**: Output image is obtained in 'output_images' directory as \"{model_name}_{TF}_detected_out.png\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d8239d",
   "metadata": {},
   "source": [
    "## Native OpenVINO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829ed88d",
   "metadata": {},
   "source": [
    "### Install openvino-dev package and Convert TF2.0 Saved model format to IR files\n",
    "In this section, we convert TensorFlow_hub 'saved_model' formats to 'IR' format using 'model optimizer : mo' available in openvino-dev package and benchmark on Native OpenVINO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610441c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.getcwd() == root_path and not os.path.exists(\"ov_ir_files\"):\n",
    "    path = os.path.join(os.getcwd(),\"ov_ir_files\")\n",
    "    os.mkdir(path)  \n",
    "\n",
    "if not os.getcwd() == root_path+\"/ov_ir_files\":\n",
    "    os.chdir(\"ov_ir_files\")\n",
    "!python3 -m pip install virtualenv && python3 -m venv openvino_env && source openvino_env/bin/activate && python3 -m pip install --upgrade pip  && pip install openvino-dev[tensorflow2]\n",
    "for model in models:\n",
    "    generate_ir(model) # Generating IR files of the model\n",
    "for model in models:\n",
    "    print(model)\n",
    "    image = root_path+\"/\"+get_image('Beach')\n",
    "    ov_run_infer(model,image)\n",
    "if not os.getcwd() == root_path:\n",
    "    os.chdir(root_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "88a5c0115b9847e114a996d3c339d6921c9a4a3391099a335a9b32b8c7932cbd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
