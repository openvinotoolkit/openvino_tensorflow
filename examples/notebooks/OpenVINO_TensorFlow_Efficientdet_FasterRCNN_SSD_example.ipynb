{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a40d338",
   "metadata": {},
   "source": [
    "# Object Detection with [OpenVINO™ integration with TensorFlow](https://github.com/openvinotoolkit/openvino_tensorflow)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898d9206",
   "metadata": {},
   "source": [
    "[OpenVINO™ integration with TensorFlow](https://github.com/openvinotoolkit/openvino_tensorflow) is designed for TensorFlow developers who want to get started with [OpenVINO™](https://www.intel.com/content/www/us/en/developer/tools/openvino-toolkit/overview.html) in their inferencing applications. This product delivers OpenVINO™ inline optimizations, which enhance inferencing performance of popular deep learning models with minimal code changes and without any accuracy drop. OpenVINO™ integration with TensorFlow accelerates inference across many AI models on a variety of Intel® silicon such as:\n",
    "\n",
    " - Intel® CPUs\n",
    " - Intel® integrated GPUs\n",
    " - Intel® Movidius™ Vision Processing Units - referred to as VPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee1e94e",
   "metadata": {},
   "source": [
    "## About this sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf17f91",
   "metadata": {},
   "source": [
    "This sample walks you through a demo of performing object detection on TensorFlow using the most popular object detection architectures on [TensorFlow Hub](https://www.tensorflow.org/hub). In the end, we will run inference on both Native TensorFlow and OpenVINO TensorFlow backends, and demonstrate the performance benefits when **OpenVINO integration with TensorFlow** is enabled.\n",
    " \n",
    "\n",
    "Firstly, we download all the models and input images. Next, we load them to be inferred on TensorFlow. After inference, the output detections are visualized. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f8d874",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "**Note**: All the prerequisites are available in this notebook and a procedure to fetch them is also explained.\n",
    "\n",
    " - Models: Efficientdet_d6_coco17_tpu-32, Faster_rcnn_resnet152_v1_1024x1024_coco17_tpu-8, and SSD_resnet50_v1_fpn_640x640_coco17_tpu-8\n",
    " - Images: Test image used from the tensorflow/models GitHub repo. You can also specify your own image as test image in [Set models and images](#Set-models-and-images) section.\n",
    " - TensorFlow: We use the TensorFlow version v2.9.2 from PyPi. Note that this version of TF is a dependency of OpenVINO-TensorFlow v2.2.0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904cfc6b",
   "metadata": {},
   "source": [
    "## About the models "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d16c23",
   "metadata": {},
   "source": [
    "\n",
    "[EfficientDet_d6](https://tfhub.dev/tensorflow/efficientdet/d6/1) is trained on the COCO 2017 dataset. This model is a combination of SSD with EfficientNet-b6 + BiFPN feature extractor, shared box predictor, and focal loss.\n",
    "\n",
    "[Faster R-CNN with Resnet-152 V1](https://tfhub.dev/tensorflow/faster_rcnn/resnet152_v1_1024x1024/1) is also trained on the COCO 2017 dataset  with training images scaled to 1024x1024.\n",
    "\n",
    "[Retinanet (SSD with Resnet 50 v1)](https://tfhub.dev/tensorflow/retinanet/resnet50_v1_fpn_640x640/1) is also trained on the COCO 2017 dataset with training images scaled to 640x640.\n",
    "\n",
    "For all three models, the input is a three-channel tensor of type tf.uint8 and shape [1, height, width, 3]. The output dictionary contains:\n",
    "\n",
    "    - num_detections: a tf.int tensor with only one value, the number of detections [N].\n",
    "    - detection_boxes: a tf.float32 tensor of shape [N, 4] containing bounding box coordinates in the following order: [ymin, xmin, ymax, xmax].\n",
    "    - detection_classes: a tf.int tensor of shape [N] containing detection class index from the label file.\n",
    "    - detection_scores: a tf.float32 tensor of shape [N] containing detection scores.\n",
    "    - raw_detection_boxes: a tf.float32 tensor of shape [1, M, 4] containing decoded detection boxes without Non-Max suppression. M is the number of raw detections.\n",
    "    - raw_detection_scores: a tf.float32 tensor of shape [1, M, 90] and contains class score logits for raw detection boxes. M is the number of raw detections.\n",
    "    - detection_anchor_indices: a tf.float32 tensor of shape [N] and contains the anchor indices of the detections after NMS.\n",
    "    - detection_multiclass_scores: a tf.float32 tensor of shape [1, N, 90] and contains class score distribution (including background) for detection boxes in the image including background class.\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66430a8c",
   "metadata": {},
   "source": [
    "## Getting Started \n",
    "\n",
    "In this section, we install TensorFlow, OpenVINO-TensorFlow, other necessary python packages, and import them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96840910",
   "metadata": {},
   "source": [
    "### Install [OpenVINO™ integration with TensorFlow](https://github.com/openvinotoolkit/openvino_tensorflow) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1445c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "root_path = os.getcwd()\n",
    "\n",
    "# Enable this variable for runtime inference optimizations\n",
    "os.environ[\"OPENVINO_TF_CONVERT_VARIABLES_TO_CONSTANTS\"] = \"1\"\n",
    "\n",
    "!python3 -m pip install --upgrade pip\n",
    "!python3 -m pip install opencv-python-headless matplotlib scipy tensorflow_hub\n",
    "\n",
    "# Install TensorFlow (v2.9.2) and OpenVINO-TensorFlow (v2.2.0)\n",
    "!python3 -m pip install --force-reinstall tensorflow==2.9.2\n",
    "!python3 -m pip install --force-reinstall openvino-tensorflow==2.2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524c95ec",
   "metadata": {},
   "source": [
    "### Import required packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ccf006",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import cv2\n",
    "import time\n",
    "import pathlib\n",
    "import colorsys\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.misc\n",
    "import numpy as np\n",
    "from six import BytesIO\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from six.moves.urllib.request import urlopen\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import openvino_tensorflow as ovtf\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bdc3eb7",
   "metadata": {},
   "source": [
    "### Clone TensorFlow models : GitHub Repository\n",
    "Clone Tensorflow/models github repository to be used in the later sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498246e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone --depth 1 https://github.com/tensorflow/models.git #This repo is cloned to use in the later context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00030cee",
   "metadata": {},
   "source": [
    "### Get Labels\n",
    "Here we open and read a label file for the MSCOCO 80 classes dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9dc348",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {}\n",
    "with open(\"mscoco_label_map.txt\") as f:\n",
    "    for label_map in f.readlines():\n",
    "        id = int(label_map.strip().split(\":\")[0])\n",
    "        label_name = label_map.strip().split(\":\")[1]\n",
    "        labels[id] = label_name\n",
    "print(labels, len(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55d2f09",
   "metadata": {},
   "source": [
    "## Get Models and Images\n",
    "\n",
    "In this section, we focus on setting up the models and inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ad8626",
   "metadata": {},
   "source": [
    "###  Set models and images\n",
    "For the model:\n",
    "Create a nested 'models' dictionary which contains model's URL [which is a tar file] as 'model_url', once the model is downloaded and untar we save the models in location as 'model_dir', save model's size as 'model_size' to be used in models IR file generation and the generated IR files are saved in a directory as 'model_ir' required for Native OpenVINO inference.\n",
    "\n",
    "For the test image:\n",
    "We are using input images available from the tensorflow/models github repo as an example. **Note**: You can also specify any image that you wish to test the models on by adding the name and location/URL of the image into the below 'images' dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c09a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A nested dictionary of with above mentioned object detection models is created to be used in later sections\n",
    "\n",
    "models = {\n",
    "    \"efficientdet_d6_coco17_tpu-32\" : {'model_url' : 'http://download.tensorflow.org/models/object_detection/tf2/20200711/efficientdet_d6_coco17_tpu-32.tar.gz','model_dir' : 'downloaded_models/efficientdet_d6_coco17_tpu-32/saved_model','model_size' : '512','model_ir' : 'ir_files/efficientdet_d6_coco17_tpu-32/saved_model.xml'},\n",
    "    \"faster_rcnn_resnet152_v1_1024x1024_coco17_tpu-8\" : {'model_url' : 'http://download.tensorflow.org/models/object_detection/tf2/20200711/faster_rcnn_resnet152_v1_1024x1024_coco17_tpu-8.tar.gz','model_dir' : 'downloaded_models/faster_rcnn_resnet152_v1_1024x1024_coco17_tpu-8/saved_model', 'model_size' : '640','model_ir' : 'ir_files/faster_rcnn_resnet152_v1_1024x1024_coco17_tpu-8/saved_model.xml'},\n",
    "    \"ssd_resnet50_v1_fpn_640x640_coco17_tpu-8\" : {'model_url' : 'http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8.tar.gz', 'model_dir' : 'downloaded_models/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/saved_model', 'model_size' : '640','model_ir' : 'ir_files/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/saved_model.xml'}\n",
    "\n",
    "}\n",
    "\n",
    "images = {\n",
    "    'Beach' : 'models/research/object_detection/test_images/image2.jpg',\n",
    "    'Dogs' : 'models/research/object_detection/test_images/image1.jpg'\n",
    "}\n",
    "\n",
    "input_image = images[\"Beach\"] #You can select the test image added in 'images' dictionary here. Like: images['your_test_image']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd98194",
   "metadata": {},
   "source": [
    "### Download models\n",
    "Create a 'downloaded_models' directory to download and save the models and untar them to use while model inferencing. Also, create 'output_images' directory to save the output images after model inferencing into that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0946dda6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if os.getcwd() == root_path and not os.path.exists(\"downloaded_models\"):\n",
    "    path = os.path.join(os.getcwd(),\"downloaded_models\")\n",
    "    os.mkdir(path)\n",
    "if os.getcwd() == root_path and not os.path.exists(\"output_images\"):\n",
    "    path = os.path.join(os.getcwd(),\"output_images\")\n",
    "    os.mkdir(path)\n",
    "    \n",
    "if not os.getcwd() == root_path+\"/downloaded_models\":\n",
    "    os.chdir(\"downloaded_models\") #changing to download_models directory\n",
    "if not os.listdir(os.getcwd()):\n",
    "    for model_name in models:\n",
    "        model_url = get_model_details(model_name)[\"model_url\"]\n",
    "        !wget \"$model_url\"\n",
    "    for model_tar in os.listdir(os.getcwd()):\n",
    "        !tar -zxvf \"$model_tar\"\n",
    "os.chdir(root_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc64718",
   "metadata": {},
   "source": [
    "## Define input processing methods\n",
    "\n",
    "In this section, we define methods useful for image and model loading, which give the right input formats to be used in inferencing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f46f823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper to fetch model details\n",
    "def get_model_details(model_name):\n",
    "    if model_name in models:\n",
    "        return models[model_name]\n",
    "\n",
    "# Helper to fetch image details\n",
    "def get_image(image_name):\n",
    "    if image_name in images:\n",
    "        return images[image_name]\n",
    "        \n",
    "# We are loading the selected model using 'tensorflow_hub.load'.\n",
    "def load_model(model_name,input_model):\n",
    "  print(f\"Loading {model_name}...\")\n",
    "  model = hub.load(input_model)\n",
    "  print(f\"{model_name} loaded successfully!\")\n",
    "  return model\n",
    "\n",
    "# We use the image URL or direct image location to read and get the input tensor\n",
    "def load_image(input_image):\n",
    "  print(\"Loading input image...\")  \n",
    "  image = None\n",
    "  if(input_image.startswith('https')):\n",
    "    response = urlopen(input_image)\n",
    "    image_data = response.read()\n",
    "    image_data = BytesIO(image_data)\n",
    "    image_data = Image.open(image_data)\n",
    "  else:\n",
    "    image_data = cv2.imread(input_image)\n",
    "\n",
    "  (img_width, img_height) = image_data.shape[1],image_data.shape[0]\n",
    "  return np.array([image_data], dtype = np.uint8), img_height, img_width"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b00ab18",
   "metadata": {},
   "source": [
    "## Define output processing methods\n",
    "\n",
    "In this section, we define methods useful post model inferencing to visualize the outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7c5925",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate colors for drawing the bounding boxes detected.\n",
    "def get_colors(class_names):\n",
    "    # Generate colors for drawing bounding boxes.\n",
    "    hsv_tuples = [\n",
    "        (x / len(class_names), 1., 1.) for x in range(len(class_names))\n",
    "    ]\n",
    "    colors = list(map(lambda x: colorsys.hsv_to_rgb(*x), hsv_tuples))\n",
    "    colors = list(\n",
    "        map(lambda x: (int(x[0] * 255), int(x[1] * 255), int(x[2] * 255)),\n",
    "            colors))\n",
    "    np.random.seed(10101)  # Fixed seed for consistent colors across runs.\n",
    "    np.random.shuffle(colors)  # Shuffle colors to decorrelate adjacent classes.\n",
    "    np.random.seed(None)  # Reset seed to default.\n",
    "    return colors\n",
    "\n",
    "# Define a method to get coordinate details of the detected bounding boxes to be drawn on the output image.\n",
    "def get_coordinates(box, img_height, img_width):\n",
    "    return [int(box[0]*img_height),int(box[1]*img_width), int(box[2]*img_height), int(box[3]*img_width)]\n",
    "\n",
    "# Define a method to add labels for the detected bounding boxes.\n",
    "def add_label(image, text, color, coords):\n",
    "    font = cv2.FONT_HERSHEY_PLAIN\n",
    "    font_scale = 1.\n",
    "    (text_width, text_height) = cv2.getTextSize(\n",
    "        text, font, fontScale=font_scale, thickness=1)[0]\n",
    "\n",
    "    padding = 5\n",
    "    rect_height = text_height + padding * 2\n",
    "    rect_width = text_width + padding * 2\n",
    "\n",
    "    (x, y) = coords\n",
    "\n",
    "    cv2.rectangle(image, (x, y), (x + rect_width, y - rect_height), color,\n",
    "                  cv2.FILLED)\n",
    "    cv2.putText(\n",
    "        image,\n",
    "        text, (x + padding, y - text_height + padding),\n",
    "        font,\n",
    "        fontScale=font_scale,\n",
    "        color=(255, 255, 255),\n",
    "        lineType=cv2.LINE_AA)\n",
    "\n",
    "    return image\n",
    "\n",
    "# Define a method for drawing the obtained bounding boxes.\n",
    "def draw_boxes(image,\n",
    "               boxes,\n",
    "               classes,\n",
    "               scores,\n",
    "               class_names,\n",
    "               colors,\n",
    "               show_score=True):\n",
    "    if classes is None or len(classes) == 0:\n",
    "        return image\n",
    "\n",
    "    for box, cls, score in zip(boxes, classes, scores):\n",
    "        ymin, xmin, ymax, xmax = box\n",
    "        \n",
    "        class_name = class_names[cls]\n",
    "        if show_score:\n",
    "            label = '{} {:.2f}'.format(class_name, score)\n",
    "        else:\n",
    "            label = '{}'.format(class_name)\n",
    "\n",
    "        # if no color info, use black(0,0,0)\n",
    "        if colors == None:\n",
    "            color = (0, 0, 0)\n",
    "        else:\n",
    "            color = colors[cls]\n",
    "        cv2.rectangle(image, (xmin, ymin), (xmax, ymax), color, 1, cv2.LINE_AA)\n",
    "        image = add_label(image, label, color, (xmin, ymin))\n",
    "\n",
    "    return image\n",
    "\n",
    "# Define a method to visualize the predictions obtained through inferencing.\n",
    "def visualize_ouput(model_name,predictions,img_height,img_width,isovtf):\n",
    "    colors = get_colors(labels)\n",
    "    class_ids = predictions[\"detection_classes\"][0].numpy().astype(\"int\")\n",
    "    scores = predictions[\"detection_scores\"][0].numpy()\n",
    "    num_detections = predictions[\"num_detections\"][0].numpy().astype(\"int\")\n",
    "    detection_boxes = predictions[\"detection_boxes\"][0].numpy()\n",
    "    conf_threshold = 0.4 # You can try increase/decrease threshold to see the output changes\n",
    "    boxes = []\n",
    "    confidence_scores = []\n",
    "    classes = []\n",
    "    for detection_index in range(num_detections):\n",
    "        if scores[detection_index]<conf_threshold:\n",
    "            continue\n",
    "        else:\n",
    "            confidence_scores.append(scores[detection_index])\n",
    "            classes.append(class_ids[detection_index])\n",
    "            boxes.append(get_coordinates(detection_boxes[detection_index], img_height, img_width))\n",
    "            \n",
    "    img_bbox = draw_boxes(cv2.imread(input_image), boxes, classes, scores,\n",
    "                        labels, colors)\n",
    "    if isovtf:\n",
    "        output_image_name = model_name + \"_OVTF\" + \"_detected_output\"\n",
    "    else:\n",
    "        output_image_name = model_name + \"_TF\" + \"_detected_output\"\n",
    "    cv2.imwrite(\"output_images/\" + output_image_name + \".png\", img_bbox)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9cde80",
   "metadata": {},
   "source": [
    "## Define inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f6a753",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inference(model,image):\n",
    "    \"\"\"Run inference to capture output and performance results\"\"\"\n",
    "    elapsed = 0.0\n",
    "    total_time = 0.0\n",
    "    num_iterations = 20 #You can increase/decrease number of iterations and see output changes\n",
    "\n",
    "    print(\"Running 5 warmup inference iterations...\")\n",
    "    # run 5 warmup iterations\n",
    "    for i in range(5):\n",
    "        predictions = model(image)\n",
    "    \n",
    "    print(\"Running %d inference iterations...\"%num_iterations)\n",
    "    # capature the average performance results\n",
    "    for i in range(num_iterations):\n",
    "        start = time.time()\n",
    "        model(image)\n",
    "        elapsed = time.time() - start\n",
    "        total_time += elapsed\n",
    "    \n",
    "    # calculate average inference time over number of iterations in milliseconds\n",
    "    # and round the number to 2 decimal points\n",
    "    average_time = round((total_time/num_iterations)*1000,2)\n",
    "                \n",
    "    return predictions, average_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57bd36df",
   "metadata": {},
   "source": [
    "## Let's infer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56772c1b",
   "metadata": {},
   "source": [
    "### Run with OpenVINO™ integration with TensorFlow enabled\n",
    "Enable OpenVINO TensorFlow with the openvino_tensorflow.enable() API and set backend name to run on OpenVINO runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a955ecf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ovtf.enable() # Enable OpenVINO Tensorflow\n",
    "\n",
    "backend_name = \"CPU\" # Define the backend to be enabled\n",
    "\n",
    "print('Available Backends:') # Print list of available backends\n",
    "backends_list = ovtf.list_backends() # To determine available backends on your system, 'list_backends' API is used\n",
    "for backend in backends_list:\n",
    "    print(f\"\\t{backend}\")\n",
    "\n",
    "ovtf.set_backend(backend_name) # Set the backend\n",
    "print(f\"OpenVINO TensorFlow is enabled and device {backend_name} is set as backend.\")\n",
    "\n",
    "image, img_height, img_width = load_image(input_image) # Loading the input image\n",
    "\n",
    "# Disable TF Logging\n",
    "os.environ[\"TF_CPP_MAX_VLOG_LEVEL\"] = \"0\"\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import absl.logging\n",
    "absl.logging.set_verbosity(absl.logging.ERROR)\n",
    "\n",
    "# Record average latency of each model in this dict\n",
    "ovtf_latency = {}\n",
    "\n",
    "# Running all the models iteratively\n",
    "for model_name in models:\n",
    "    input_model = get_model_details(model_name)[\"model_dir\"] # Get model location\n",
    "    model = load_model(model_name,input_model) # Loading the model\n",
    "    predictions,average_time = run_inference(model,image) # Running inference\n",
    "    visualize_ouput(model_name, predictions, img_height, img_width, 1) # Visualizing the output. Here '1' is set to indicate model run on OVTF\n",
    "    ovtf_latency[model_name] = int(average_time)\n",
    "    print(f\"Inference Successfully completed on OpenVINO TensorFlow..! {model_name} model run on {backend_name} in {average_time} ms\\n\"),\n",
    "    print(f\"-----------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b034917",
   "metadata": {},
   "source": [
    "### Run with native TensorFlow\n",
    "Disable OpenVINO-TensorFlow with the openvino_tensorflow.disable() API to run on native TensorFlow runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b381bbc6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ovtf.disable() # Disable OpenVINO Tensorflow\n",
    "print(\"OpenVINO TensorFlow is disabled\\n\")\n",
    "\n",
    "backend_name = \"CPU\" # Define the backend\n",
    "\n",
    "# Record average latency of each model in this dict\n",
    "tf_latency = {}\n",
    "\n",
    "image, img_height, img_width = load_image(input_image) # Loading the input_image\n",
    "for model_name in models:\n",
    "    input_model = get_model_details(model_name)[\"model_dir\"] # Get model location\n",
    "    model = load_model(model_name,input_model) # Loading the model\n",
    "    predictions,average_time = run_inference(model,image) # Running inference\n",
    "    visualize_ouput(model_name, predictions, img_height, img_width, 0) # Visualizing the output. Here '0' is set to indicate model run on TF\n",
    "    tf_latency[model_name] = int(average_time)\n",
    "    print(f\"Inference Successfully completed on OpenVINO TensorFlow..! {model_name} model run on {backend_name} in {average_time} ms\\n\"),\n",
    "    print(f\"-----------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b1f131",
   "metadata": {},
   "source": [
    "### Let's visualize the inferred images between Native TensorFlow and OpenVINO TensorFlow\n",
    "\n",
    "Here we visually compare the output images of the Faster RCNN ResNet 152 v1 1024x1024 model to ensure there's no difference in the output boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97bace05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "import numpy as np\n",
    "\n",
    "im_tf = cv2.imread(\"output_images/faster_rcnn_resnet152_v1_1024x1024_coco17_tpu-8_TF_detected_output.png\")\n",
    "im_ovtf = cv2.imread(\"output_images/faster_rcnn_resnet152_v1_1024x1024_coco17_tpu-8_OVTF_detected_output.png\")\n",
    "\n",
    "fig = plt.figure(figsize=(32, 20))\n",
    "grid = ImageGrid(fig, 111,  # similar to subplot(111)\n",
    "                 nrows_ncols=(2, 1),  # creates 2x2 grid of axes\n",
    "                 axes_pad=0.5,  # pad between axes in inch.\n",
    "                 share_all=True\n",
    "                 )\n",
    "grid[0].get_yaxis().set_ticks([])\n",
    "grid[0].get_xaxis().set_ticks([])\n",
    "\n",
    "grid[0].set_title(\"Native TensorFlow\", fontdict=None, loc='center', color = \"k\")\n",
    "grid[1].set_title(\"OpenVINO TensorFlow\", fontdict=None, loc='center', color = \"k\")\n",
    "\n",
    "for ax, im in zip(grid, [im_tf, im_ovtf]):\n",
    "    # Iterating over the grid returns the Axes.\n",
    "    ax.imshow(im)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6723674b",
   "metadata": {},
   "source": [
    "# Let's plot the performance results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a1e611",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init a 16x9 plot\n",
    "fig, ax = plt.subplots(figsize=(16, 9))\n",
    "\n",
    "# Plot the values\n",
    "Y = np.arange(len(ovtf_latency))\n",
    "ax.barh(Y, list(tf_latency.values()), height=0.2)\n",
    "ax.barh(Y+0.2, list(ovtf_latency.values()), height=0.2)\n",
    "\n",
    "# Set Y-axis labels and add Legend\n",
    "plt.yticks(Y, tf_latency.keys())\n",
    "ax.legend(('TF Latency','OVTF Latency'))\n",
    "\n",
    "# Remove axes splines\n",
    "for s in ['top', 'bottom', 'left', 'right']:\n",
    "    ax.spines[s].set_visible(False)\n",
    "\n",
    "# Add padding between axes and labels\n",
    "ax.xaxis.set_tick_params(pad = 5)\n",
    "ax.yaxis.set_tick_params(pad = 10)\n",
    " \n",
    "# Add x, y gridlines\n",
    "ax.grid(visible = True, color ='grey',\n",
    "        linestyle ='-.', linewidth = 0.5,\n",
    "        alpha = 0.2)\n",
    " \n",
    "# Show top values\n",
    "ax.invert_yaxis()\n",
    " \n",
    "# Add annotation to bars\n",
    "for i in ax.patches:\n",
    "    plt.text(i.get_width()+10, i.get_y()+0.125,\n",
    "             str(round((i.get_width()), 2)),\n",
    "             fontsize = 10, fontweight ='bold',\n",
    "             color ='grey')\n",
    " \n",
    "# Add Plot Title\n",
    "ax.set_title('Inference latency improvements done by OpenVINO integration with TensorFlow\\n(Lower is better)', loc='left', fontweight='bold')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.5 ('venv-tf-py3': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "5f34e77ed429b9f682550cc2b07df7918866c9913f0a4cd2b9928f7e226e86ab"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
