{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zEl4DrmhGyot"
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/openvinotoolkit/openvino_tensorflow/blob/master/examples/notebooks/Colab_OpenVINO_TensorFlow_object_detection_example.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "atwwZdgc3d3_"
   },
   "source": [
    "\n",
    "\n",
    "#**Object Detection with OpenVINO™ integration with TensorFlow**:\n",
    "\n",
    "OpenVINO™ integration with TensorFlow is designed for TensorFlow developers who want to get started with OpenVINO™ in their inferencing applications. This product effectively delivers OpenVINO™ inline optimizations which enhance inferencing performance with minimal code modifications. OpenVINO™ integration with TensorFlow accelerates inference across many AI models on a variety of Intel® silicon such as: \n",
    "*   Intel® CPUs\n",
    "*   Intel® integrated GPUs\n",
    "*   Intel® Movidius™ Vision Processing Units - referred to as VPU\n",
    "*   Intel® Vision Accelerator Design with 8 Intel Movidius™ MyriadX VPUs - referred to as VAD-M or HDDL\n",
    "\n",
    "**Overview**\n",
    "\n",
    "The following code demonstrates acceleration of YOLOv4 using OpenVINO™ integration with TensorFlow. We compare the performance of YOLOv4 with and without OpenVINO™ integration with TensorFlow. This model is a real time object detection algorithm that identifies objects in images & videos. It detects these objects by using features learned by a deep convolutional neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hk5UWnY6BDpz"
   },
   "outputs": [],
   "source": [
    "TF_VERSION = \"2.7.0\"\n",
    "OVTF_VERSION = \"1.1.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uOk7Kisgh1Nw",
    "outputId": "f71ba431-8ae7-4e9e-b951-1a34f2e610b9"
   },
   "outputs": [],
   "source": [
    "# Upload the required wheel files, models and images in a google drive folder\n",
    "# Uncomment and run the below command to copy them in your current workspace\n",
    "#!cp /content/drive/MyDrive/TF-OV/working_dir_files/* . \n",
    "\n",
    "!python3 -m pip -q install --upgrade pip\n",
    "!python3 -m pip -q install pillow\n",
    "!python3 -m pip -q install keras_applications\n",
    "\n",
    "# Install TensorFlow and OpenVINO-TensorFlow only if they aren't found\n",
    "!if python3 -c \"import tensorflow\"; then echo \"Installed. Skipping.\"; else echo \"Not Found. Installing.\"; python3 -m pip -q install tensorflow=={TF_VERSION}; fi\n",
    "!if python3 -c \"import openvino_tensorflow\"; then echo \"Installed. Skipping.\"; else echo \"Not Found. Installing.\"; python3 -m pip -q install openvino-tensorflow=={TF_VERSION}; fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZajQSurMBDp3"
   },
   "source": [
    "Change ```OVTF_DIR``` value to directory where you have cloned openvino_tensorflow directory\n",
    "\n",
    "Ex. if you have /home/\\<username\\>/openvino_tensorflow then OVTF_DIR value will be /home/\\<username\\>/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5ItnXT0-BDp4"
   },
   "outputs": [],
   "source": [
    "OVTF_DIR = \"/\"\n",
    "RAW_GITHUB_COMMON = \"https://raw.githubusercontent.com/openvinotoolkit/openvino_tensorflow/master/examples/common/\"\n",
    "GITHUB_EXAMPLES = \"https://github.com/openvinotoolkit/openvino_tensorflow/raw/master/examples/data/\"\n",
    "RAW_GITHUB_EXAMPLES = \"https://raw.githubusercontent.com/openvinotoolkit/openvino_tensorflow/master/examples/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5mJByr6p9Olq",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "files = os.listdir('.')\n",
    "if ('common' not in files or 'examples' not in files) and 'openvino_tensorflow' not in os.listdir(OVTF_DIR):\n",
    "    !mkdir ./common\n",
    "    !wget {RAW_GITHUB_COMMON}/post_process.py -O ./common/post_process.py\n",
    "    !wget {RAW_GITHUB_COMMON}/pre_process.py -O ./common/pre_process.py\n",
    "    !wget {RAW_GITHUB_COMMON}/utils.py -O ./common/utils.py\n",
    "    !mkdir -p ./examples/data\n",
    "    !wget {GITHUB_EXAMPLES}/grace_hopper.jpg -O ./examples/data/grace_hopper.jpg\n",
    "    !wget {GITHUB_EXAMPLES}/yolov4_anchors.txt -O ./examples/data/yolov4_anchors.txt\n",
    "    !wget {RAW_GITHUB_EXAMPLES}/convert_yolov4.sh -O ./examples/convert_yolov4.sh\n",
    "    !wget {RAW_GITHUB_EXAMPLES}/keras_to_tensorflow.patch -O ./examples/keras_to_tensorflow.patch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "--qjoum7BDp5"
   },
   "source": [
    "### This additional check is to faciliate common package import statement helpful in docker container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YISvaMlnBDp6"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "if 'openvino_tensorflow' in os.listdir(OVTF_DIR):\n",
    "    sys_append = os.path.abspath(OVTF_DIR + \"/openvino_tensorflow/examples/\")\n",
    "    sys.path.append(sys_append)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1EImyzDiiHGW"
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import openvino_tensorflow as ovtf\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from common.utils import get_input_mode, get_colors, draw_boxes, get_anchors, rename_file\n",
    "from common.pre_process import preprocess_image_yolov3 as preprocess_image\n",
    "from common.post_process import yolo3_postprocess_np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kVYX3McBIafu"
   },
   "source": [
    "# Let's get the model\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lLCEnbd6QSqw",
    "outputId": "d05bbf5a-56ee-46bc-a852-6cbaaf08aec1",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Download and Convert the YoloV4 model\n",
    "files = os.listdir('.')\n",
    "if 'examples' in files:\n",
    "    path = \"examples\"\n",
    "else:\n",
    "    path = \"{0}/openvino_tensorflow/examples/\".format(OVTF_DIR)\n",
    "%cd {path}\n",
    "!chmod +x convert_yolov4.sh && bash convert_yolov4.sh\n",
    "# Once the model conversion is completed; move back to outside of examples directory\n",
    "%cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MKws1vbpypgp"
   },
   "outputs": [],
   "source": [
    "def load_coco_names(file_name):\n",
    "    \"\"\"Parses the label file with only class names,\n",
    "      and returns a dictionary mapping the class IDs to class names.\n",
    "    \"\"\"\n",
    "    names = {}\n",
    "    with open(file_name) as f:\n",
    "        for id_, name in enumerate(f):\n",
    "            names[id_] = name\n",
    "    return names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q1IK7afTPtIv"
   },
   "outputs": [],
   "source": [
    "def load_labels(label_file):\n",
    "    \"\"\"Parses the label file, assuming that labels are separated with a newline\n",
    "       in the file and returns the list of labels.\n",
    "    \"\"\"  \n",
    "    label = []\n",
    "    proto_as_ascii_lines = tf.io.gfile.GFile(label_file).readlines()\n",
    "    for l in proto_as_ascii_lines:\n",
    "        label.append(l.rstrip())\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6P-q263g1BtS"
   },
   "outputs": [],
   "source": [
    "def infer_openvino_tensorflow(model_file, image_file , input_height, input_width, label_file, anchor_file, conf_threshold, iou_threshold):\n",
    "    \"\"\"Takes the tensorflow model and all other input parameters as arguments. \n",
    "       Runs inference with the object detection model and prints the predictions.\n",
    "    \"\"\"\n",
    "    print(\"CREATE MODEL - BEGIN\")\n",
    "\n",
    "    # Load model and process input image\n",
    "    model =     model = tf.saved_model.load(model_file)\n",
    "    print(\"CREATE MODEL - END\")\n",
    "\n",
    "    if label_file:\n",
    "        classes = load_coco_names(label_file)\n",
    "        labels = load_labels(label_file)\n",
    "        colors = get_colors(labels)\n",
    "\n",
    "    if anchor_file:\n",
    "        anchors = get_anchors(anchor_file)\n",
    "\n",
    "    print(\"PREDICTION - BEGIN\")\n",
    "    \n",
    "    #Preprocess Image\n",
    "    image = Image.open(image_file)\n",
    "    img = np.asarray(image)\n",
    "    image_width, image_height = image.size\n",
    "    img_resized = tf.convert_to_tensor(preprocess_image(image, (input_height, input_width)))\n",
    "\n",
    "    # Warmup\n",
    "    detected_boxes = model(img_resized)\n",
    "    # Run\n",
    "    import time\n",
    "    start = time.time()\n",
    "    detected_boxes = model(img_resized)\n",
    "    elapsed = time.time() - start\n",
    "    print('Inference time in ms: %f' % (elapsed * 1000))\n",
    "    print(\"PREDICTION - END\")  \n",
    "    \n",
    "    image_shape = tuple((image_height, image_width))  \n",
    "    # apply non max suppresion, draw boxes and save updated image\n",
    "    out_boxes, out_classes, out_scores = yolo3_postprocess_np(\n",
    "            detected_boxes,\n",
    "            image_shape,\n",
    "            anchors,\n",
    "            len(labels), (input_height, input_width),\n",
    "            max_boxes=10,\n",
    "            confidence=conf_threshold,\n",
    "            iou_threshold=iou_threshold,\n",
    "            elim_grid_sense=True)\n",
    "    img_bbox = draw_boxes(img, out_boxes, out_classes, out_scores,\n",
    "                        labels, colors)\n",
    "    cv2.imwrite(\"detections.jpg\", img_bbox)\n",
    "    if output_dir:\n",
    "        image.save(os.path.join(output_dir, \"detections.jpg\"))\n",
    "    else:\n",
    "        image.save(\"detections.jpg\")\n",
    "    plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tDQDLFx69izd"
   },
   "source": [
    "# Now lets infer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ChASQZvpU3VP"
   },
   "source": [
    "*   Set all the parameters needed for inference\n",
    "*   Enable OpenVINO™ integration with TensorFlow, and set Backend in just a few simple lines of code to boost performace\n",
    "*   Infer the input image \n",
    "*   Output the predicted bounding box on the image, and the inference time with OpenVINO™ integration with TensorFlow enabled\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 442
    },
    "id": "i8hOGhl51MD-",
    "outputId": "1f889324-e047-4075-9611-68f7a07fe4d1"
   },
   "outputs": [],
   "source": [
    "input_file = \"examples/data/grace_hopper.jpg\"\n",
    "model_file = \"examples/data/yolo_v4\"\n",
    "label_file = \"examples/data/coco.names\"\n",
    "anchor_file = \"examples/data/yolov4_anchors.txt\"\n",
    "input_height = 416\n",
    "input_width = 416\n",
    "backend_name = \"CPU\"\n",
    "output_dir = \".\"\n",
    "conf_threshold = 0.6\n",
    "iou_threshold = 0.5\n",
    "\n",
    "#Print list of available backends\n",
    "print('Available Backends:')\n",
    "backends_list = ovtf.list_backends()\n",
    "for backend in backends_list:\n",
    "    print(backend)\n",
    "ovtf.set_backend(backend_name)\n",
    "\n",
    "print(\"OpenVINO TensorFlow is enabled\")\n",
    "infer_openvino_tensorflow(model_file, input_file, input_height, input_width, label_file, anchor_file, conf_threshold, iou_threshold )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LQjM-ohlWblT"
   },
   "source": [
    "*   Disable OpenVINO™ integration with TensorFlow to gauge the achieved performance boost\n",
    "*   Infer the input image again\n",
    "*   Output the predicted bounding box on the image, and the inference time with OpenVINO™ integration with TensorFlow disabled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "id": "ffk49RJz1sKa",
    "outputId": "a0a3489f-81e5-4c4d-92cd-ac112dadb46b",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ovtf.disable() ## Disabling OVTF\n",
    "print(\"OpenVINO TensorFlow is disabled\")\n",
    "infer_openvino_tensorflow(model_file, input_file, input_height, input_width, label_file, anchor_file, conf_threshold, iou_threshold )\n",
    "ovtf.enable()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Colab_OpenVINO_TensorFlow_object_detection_example_mod.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
