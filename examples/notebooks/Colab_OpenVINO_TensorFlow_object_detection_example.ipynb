{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zEl4DrmhGyot"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/openvinotoolkit/openvino_tensorflow/blob/master/examples/notebooks/Colab_OpenVINO_TensorFlow_object_detection_example.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "atwwZdgc3d3_"
      },
      "source": [
        "\n",
        "\n",
        "#**Object Detection with OpenVINO™ integration with TensorFlow**:\n",
        "\n",
        "OpenVINO™ integration with TensorFlow is designed for TensorFlow developers who want to get started with OpenVINO™ in their inferencing applications. This product effectively delivers OpenVINO™ inline optimizations which enhance inferencing performance with minimal code modifications. OpenVINO™ integration with TensorFlow accelerates inference across many AI models on a variety of Intel® silicon such as: \n",
        "*   Intel® CPUs\n",
        "*   Intel® integrated GPUs\n",
        "*   Intel® Movidius™ Vision Processing Units - referred to as VPU\n",
        "*   Intel® Vision Accelerator Design with 8 Intel Movidius™ MyriadX VPUs - referred to as VAD-M or HDDL\n",
        "\n",
        "**Overview**\n",
        "\n",
        "The following code demonstrates acceleration of YOLOv4 using OpenVINO™ integration with TensorFlow. We compare the performance of YOLOv4 with and without OpenVINO™ integration with TensorFlow. This model is a real time object detection algorithm that identifies objects in images & videos. It detects these objects by using features learned by a deep convolutional neural network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uOk7Kisgh1Nw"
      },
      "outputs": [],
      "source": [
        "# Upload the required wheel files, models and images in a google drive folder\n",
        "# Uncomment and run the below command to copy them in your current workspace\n",
        "#!cp /content/drive/MyDrive/TF-OV/working_dir_files/* . \n",
        "\n",
        "!pip3 -q install --upgrade pip\n",
        "!pip3 -q install pillow\n",
        "!pip3 -q install keras_applications"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sgy6S1B_rW9d"
      },
      "outputs": [],
      "source": [
        "!ldd --version"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0NqXHZ9pg82"
      },
      "source": [
        "## INSTALL OpenVINO™ integration with TensorFlow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jtoL7InRjmPy"
      },
      "outputs": [],
      "source": [
        "# Install stock TensorFlow\n",
        "!pip3 -q install tensorflow==2.7.0\n",
        "\n",
        "# Install OpenVINO™ integration with TensorFlow\n",
        "!pip3 -q install openvino-tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download OpenVINO TensorFlow repository\n",
        "!git clone --quiet https://github.com/openvinotoolkit/openvino_tensorflow\n",
        "%cd openvino_tensorflow\n",
        "!git submodule init\n",
        "!git submodule update --recursive\n"
      ],
      "metadata": {
        "id": "xKyZlLQGqLsc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1EImyzDiiHGW"
      },
      "outputs": [],
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import openvino_tensorflow as ovtf\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import sys\n",
        "sys.path.append(os.getcwd() + '/examples')\n",
        "from common.utils import get_input_mode, get_colors, draw_boxes, get_anchors, rename_file\n",
        "from common.pre_process import preprocess_image_yolov3 as preprocess_image\n",
        "from common.post_process import yolo3_postprocess_np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kVYX3McBIafu"
      },
      "source": [
        "# Let's get the model\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lLCEnbd6QSqw"
      },
      "outputs": [],
      "source": [
        "# Download and Convert the YoloV4 model\n",
        "%cd examples/\n",
        "!apt install -qq virtualenv python3-venv\n",
        "!chmod +x convert_yolov4.sh && bash convert_yolov4.sh &>/dev/null\n",
        "%cd ../"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MKws1vbpypgp"
      },
      "outputs": [],
      "source": [
        "def load_coco_names(file_name):\n",
        "    \"\"\"Parses the label file with only class names,\n",
        "      and returns a dictionary mapping the class IDs to class names.\n",
        "    \"\"\"\n",
        "    names = {}\n",
        "    with open(file_name) as f:\n",
        "        for id, name in enumerate(f):\n",
        "            names[id] = name\n",
        "    return names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q1IK7afTPtIv"
      },
      "outputs": [],
      "source": [
        "def load_labels(label_file):\n",
        "    \"\"\"Parses the label file, assuming that labels are separated with a newline\n",
        "       in the file and returns the list of labels.\n",
        "    \"\"\"  \n",
        "    label = []\n",
        "    proto_as_ascii_lines = tf.io.gfile.GFile(label_file).readlines()\n",
        "    for l in proto_as_ascii_lines:\n",
        "        label.append(l.rstrip())\n",
        "    return label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6P-q263g1BtS"
      },
      "outputs": [],
      "source": [
        "def infer_openvino_tensorflow(model_file, image_file , input_height, input_width, label_file, anchor_file, conf_threshold, iou_threshold):\n",
        "    \"\"\"Takes the tensorflow model and all other input parameters as arguments. \n",
        "       Runs inference with the object detection model and prints the predictions.\n",
        "    \"\"\"\n",
        "    print(\"CREATE MODEL - BEGIN\")\n",
        "\n",
        "    # Load model and process input image\n",
        "    model =     model = tf.saved_model.load(model_file)\n",
        "    print(\"CREATE MODEL - END\")\n",
        "\n",
        "    if label_file:\n",
        "        classes = load_coco_names(label_file)\n",
        "        labels = load_labels(label_file)\n",
        "        colors = get_colors(labels)\n",
        "\n",
        "    if anchor_file:\n",
        "        anchors = get_anchors(anchor_file)\n",
        "\n",
        "    print(\"PREDICTION - BEGIN\")\n",
        "    \n",
        "    #Preprocess Image\n",
        "    image = Image.open(image_file)\n",
        "    img = np.asarray(image)\n",
        "    image_width, image_height = image.size\n",
        "    img_resized = tf.convert_to_tensor(preprocess_image(image, (input_height, input_width)))\n",
        "\n",
        "    # Warmup\n",
        "    detected_boxes = model(img_resized)\n",
        "    # Run\n",
        "    import time\n",
        "    start = time.time()\n",
        "    detected_boxes = model(img_resized)\n",
        "    elapsed = time.time() - start\n",
        "    print('Inference time in ms: %f' % (elapsed * 1000))\n",
        "    print(\"PREDICTION - END\")  \n",
        "    \n",
        "    image_shape = tuple((image_height, image_width))  \n",
        "    # apply non max suppresion, draw boxes and save updated image\n",
        "    out_boxes, out_classes, out_scores = yolo3_postprocess_np(\n",
        "            detected_boxes,\n",
        "            image_shape,\n",
        "            anchors,\n",
        "            len(labels), (input_height, input_width),\n",
        "            max_boxes=10,\n",
        "            confidence=conf_threshold,\n",
        "            iou_threshold=iou_threshold,\n",
        "            elim_grid_sense=True)\n",
        "    img_bbox = draw_boxes(img, out_boxes, out_classes, out_scores,\n",
        "                        labels, colors)\n",
        "    cv2.imwrite(\"detections.jpg\", img_bbox)\n",
        "    if output_dir:\n",
        "        image.save(os.path.join(output_dir, \"detections.jpg\"))\n",
        "    else:\n",
        "        image.save(\"detections.jpg\")\n",
        "    plt.imshow(img)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDQDLFx69izd"
      },
      "source": [
        "# Now lets infer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ChASQZvpU3VP"
      },
      "source": [
        "*   Set all the parameters needed for inference\n",
        "*   Enable OpenVINO™ integration with TensorFlow, and set Backend in just a few simple lines of code to boost performace\n",
        "*   Infer the input image \n",
        "*   Output the predicted bounding box on the image, and the inference time with OpenVINO™ integration with TensorFlow enabled\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i8hOGhl51MD-"
      },
      "outputs": [],
      "source": [
        "   input_file = \"examples/data/grace_hopper.jpg\"\n",
        "   model_file = \"examples/data/yolo_v4\"\n",
        "   label_file = \"examples/data/coco.names\"\n",
        "   anchor_file = \"examples/data/yolov4_anchors.txt\"\n",
        "   input_height = 416\n",
        "   input_width = 416\n",
        "   backend_name = \"CPU\"\n",
        "   output_dir = \".\"\n",
        "   conf_threshold = 0.6\n",
        "   iou_threshold = 0.5\n",
        "\n",
        "   #Print list of available backends\n",
        "   print('Available Backends:')\n",
        "   backends_list = ovtf.list_backends()\n",
        "   for backend in backends_list:\n",
        "       print(backend)\n",
        "   ovtf.set_backend(backend_name)\n",
        "\n",
        "   print(\"OpenVINO TensorFlow is enabled\")\n",
        "   infer_openvino_tensorflow(model_file, input_file, input_height, input_width, label_file, anchor_file, conf_threshold, iou_threshold )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQjM-ohlWblT"
      },
      "source": [
        "*   Disable OpenVINO™ integration with TensorFlow to gauge the achieved performance boost\n",
        "*   Infer the input image again\n",
        "*   Output the predicted bounding box on the image, and the inference time with OpenVINO™ integration with TensorFlow disabled\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ffk49RJz1sKa"
      },
      "outputs": [],
      "source": [
        "#Disable\n",
        "ovtf.disable()\n",
        "print(\"\")\n",
        "print(\"\")\n",
        "print(\"OpenVINO TensorFlow is disabled\")\n",
        "infer_openvino_tensorflow(model_file, input_file, input_height, input_width, label_file, anchor_file, conf_threshold, iou_threshold )\n",
        "ovtf.enable()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Colab_OpenVINO_TensorFlow_object_detection_example.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}