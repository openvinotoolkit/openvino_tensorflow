{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zEl4DrmhGyot"
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/openvinotoolkit/openvino_tensorflow/blob/master/docs/cloud_instructions/Colab_OpenVINO_TensorFlow_object_detection_example.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m0NqXHZ9pg82"
   },
   "source": [
    "## INSTALL OpenVINO™ integration with TensorFlow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uOk7Kisgh1Nw",
    "outputId": "06d0dac9-f998-41c7-d48d-135ee2e042d2"
   },
   "outputs": [],
   "source": [
    "# Upload the required wheel files, models and images in a google drive folder\n",
    "# Uncomment and run the below command to copy them in your current workspace\n",
    "#!cp /content/drive/MyDrive/TF-OV/working_dir_files/* . \n",
    "\n",
    "!pip -q install --upgrade pip\n",
    "!pip -q install pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sgy6S1B_rW9d",
    "outputId": "b40a4fc2-fcdd-4296-d120-2eac67a9df05"
   },
   "outputs": [],
   "source": [
    "!ldd --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kVYX3McBIafu"
   },
   "source": [
    "# Lets get the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jtoL7InRjmPy",
    "outputId": "f1f91405-7ca7-4193-a6e3-8a8d597e9260"
   },
   "outputs": [],
   "source": [
    "#steps to get yolov3_darknet\n",
    "!git clone --quiet https://github.com/openvinotoolkit/openvino_tensorflow\n",
    "%cd openvino_tensorflow\n",
    "!git submodule init\n",
    "!git submodule update --recursive\n",
    "\n",
    "%cd examples/\n",
    "!apt install -qq virtualenv python3-venv\n",
    "!chmod +x convert_yolov3.sh && bash convert_yolov3.sh &>/dev/null\n",
    "%cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B8JTdrlue6Yr",
    "outputId": "8048bcf7-ab1f-4af0-abb5-4717580b7396"
   },
   "outputs": [],
   "source": [
    "# Install stock TensorFlow\n",
    "!pip -q install tensorflow==2.5.1 \n",
    "\n",
    "# Install OpenVINO™ integration with TensorFlow\n",
    "!pip -q install openvino-tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tDQDLFx69izd"
   },
   "source": [
    "# Now lets infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "1EImyzDiiHGW"
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "from tensorflow.keras import backend as K\n",
    "from IPython.display import HTML\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import openvino_tensorflow as ovtf\n",
    "import time\n",
    "from PIL import Image, ImageFont, ImageDraw\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "sys.path.append(os.getcwd() + '/examples')\n",
    "from common.utils import get_input_mode, get_colors, draw_boxes, get_anchors, rename_file\n",
    "from common.pre_process import preprocess_image_yolov3 as preprocess_image\n",
    "from common.post_process import yolo3_postprocess_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "BwPfurPbFhzI"
   },
   "outputs": [],
   "source": [
    "def load_coco_names(file_name):\n",
    "    names = {}\n",
    "    with open(file_name) as f:\n",
    "        for id, name in enumerate(f):\n",
    "            names[id] = name\n",
    "    return names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "F7qnLOKvLvdk"
   },
   "outputs": [],
   "source": [
    "def load_labels(label_file):\n",
    "    label = []\n",
    "    proto_as_ascii_lines = tf.io.gfile.GFile(label_file).readlines()\n",
    "    for l in proto_as_ascii_lines:\n",
    "        label.append(l.rstrip())\n",
    "    return label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "byhRm6n6ki8Q"
   },
   "outputs": [],
   "source": [
    "def infer_openvino_tensorflow(model_file, image_file , input_height, input_width, label_file, anchor_file, conf_threshold, iou_threshold):\n",
    "    print(\"CREATE MODEL - BEGIN\")\n",
    "\n",
    "    # Load model and process input image\n",
    "    model =     model = tf.saved_model.load(model_file)\n",
    "    print(\"CREATE MODEL - END\")\n",
    "\n",
    "    if label_file:\n",
    "        classes = load_coco_names(label_file)\n",
    "        labels = load_labels(label_file)\n",
    "        colors = get_colors(labels)\n",
    "\n",
    "    if anchor_file:\n",
    "        anchors = get_anchors(anchor_file)\n",
    "\n",
    "    print(\"PREDICTION - BEGIN\")\n",
    "    \n",
    "    #Preprocess Image\n",
    "    image = Image.open(image_file)\n",
    "    img = np.asarray(image)\n",
    "    image_width, image_height = image.size\n",
    "    img_resized = tf.convert_to_tensor(preprocess_image(image, (input_height, input_width)))\n",
    "\n",
    "    # Warmup\n",
    "    detected_boxes = model(img_resized)\n",
    "    # Run\n",
    "    import time\n",
    "    start = time.time()\n",
    "    detected_boxes = model(img_resized)\n",
    "    elapsed = time.time() - start\n",
    "    print('Inference time in ms: %f' % (elapsed * 1000))\n",
    "    print(\"PREDICTION - END\")  \n",
    "    \n",
    "    image_shape = tuple((image_height, image_width))  \n",
    "    # apply non max suppresion, draw boxes and save updated image\n",
    "    out_boxes, out_classes, out_scores = yolo3_postprocess_np(\n",
    "            detected_boxes,\n",
    "            image_shape,\n",
    "            anchors,\n",
    "            len(labels), (input_height, input_width),\n",
    "            max_boxes=10,\n",
    "            confidence=conf_threshold,\n",
    "            iou_threshold=iou_threshold,\n",
    "            elim_grid_sense=True)\n",
    "    img_bbox = draw_boxes(img, out_boxes, out_classes, out_scores,\n",
    "                        labels, colors)\n",
    "    cv2.imwrite(\"detections.jpg\", img_bbox)\n",
    "    if output_dir:\n",
    "        image.save(os.path.join(output_dir, \"detections.jpg\"))\n",
    "    else:\n",
    "        image.save(\"detections.jpg\")\n",
    "    plt.imshow(img)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 422
    },
    "id": "6wyXyuylGlRP",
    "outputId": "6c00102e-0f4f-4e9e-90ab-afe380567b3c"
   },
   "outputs": [],
   "source": [
    "   input_file = \"examples/data/grace_hopper.jpg\"\n",
    "   model_file = \"examples/data/yolo_v3_darknet_2\"\n",
    "   label_file = \"examples/data/coco.names\"\n",
    "   anchor_file = \"examples/data/yolov3_anchors.txt\"\n",
    "   input_height = 416\n",
    "   input_width = 416\n",
    "   backend_name = \"CPU\"\n",
    "   output_dir = \".\"\n",
    "   conf_threshold = 0.6\n",
    "   iou_threshold = 0.5\n",
    "\n",
    "   #Print list of available backends\n",
    "   print('Available Backends:')\n",
    "   backends_list = ovtf.list_backends()\n",
    "   for backend in backends_list:\n",
    "       print(backend)\n",
    "   ovtf.set_backend(backend_name)\n",
    "\n",
    "   print(\"OpenVINO TensorFlow is enabled\")\n",
    "   infer_openvino_tensorflow(model_file, input_file, input_height, input_width, label_file, anchor_file, conf_threshold, iou_threshold )\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 422
    },
    "id": "s60Eml7RKbCp",
    "outputId": "ed3bc4cd-500a-4c26-a042-a3d7ab0a6ed9"
   },
   "outputs": [],
   "source": [
    "#Disable\n",
    "ovtf.disable()\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(\"OpenVINO TensorFlow is disabled\")\n",
    "infer_openvino_tensorflow(model_file, input_file, input_height, input_width, label_file, anchor_file, conf_threshold, iou_threshold )\n",
    "ovtf.enable()\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of Colab_OpenVINO_TensorFlow_object_detection_example.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
